<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>K-均值聚类 | 哈皮🐖</title><meta name="description" content="K-均值聚类"><meta name="keywords" content="聚类"><meta name="author" content="Paul Yu"><meta name="copyright" content="Paul Yu"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin><link rel="preconnect" href="//busuanzi.ibruce.info"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="K-均值聚类"><meta name="twitter:description" content="K-均值聚类"><meta name="twitter:image" content="http://image-paul-blogs.test.upcdn.net/blog/a7.jpg"><meta property="og:type" content="article"><meta property="og:title" content="K-均值聚类"><meta property="og:url" content="http://yoursite.com/2020/03/01/K-%E5%9D%87%E5%80%BC%E8%81%9A%E7%B1%BB/"><meta property="og:site_name" content="哈皮🐖"><meta property="og:description" content="K-均值聚类"><meta property="og:image" content="http://image-paul-blogs.test.upcdn.net/blog/a7.jpg"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>const autoChangeMode = 'false'
var t = Cookies.get("theme");
if (autoChangeMode == '1'){
const isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
const isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
const isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

if (t === undefined){
  if (isLightMode) activateLightMode()
  else if (isDarkMode) activateDarkMode()
  else if (isNotSpecified || hasNoSupport){
    console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
    now = new Date();
    hour = now.getHours();
    isNight = hour < 6 || hour >= 18
    isNight ? activateDarkMode() : activateLightMode()
}
} else if (t == 'light') activateLightMode()
else activateDarkMode()


} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="http://yoursite.com/2020/03/01/K-%E5%9D%87%E5%80%BC%E8%81%9A%E7%B1%BB/"><link rel="prev" title="可视化之Matplotlib(一)" href="http://yoursite.com/2020/03/12/%E5%8F%AF%E8%A7%86%E5%8C%96%E4%B9%8BMatplotlib(%E4%B8%80)/"><link rel="next" title="流量分类论文总结" href="http://yoursite.com/2020/02/24/%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    title: 'Snackbar.bookmark.title',
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: {"text":"富强,民主,文明,和谐,自由,平等,公正,法治,爱国,敬业,诚信,友善","fontSize":"15px"},
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  baiduPush: false,
  isHome: false,
  isPost: true
  
}</script><meta name="generator" content="Hexo 4.2.0"></head><body><header> <div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">哈皮🐖</a></span><span class="toggle-menu pull_right close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/download/"><i class="fa-fw fa fa-download"></i><span> 下载站</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> 娱乐</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/gallery/"><i class="fa-fw fa fa-picture-o"></i><span> 相册</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div></div></span></div></header><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">15</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">11</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">12</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/download/"><i class="fa-fw fa fa-download"></i><span> 下载站</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> 娱乐</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/gallery/"><i class="fa-fw fa fa-picture-o"></i><span> 相册</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div></div></div></div><div id="body-wrap"><main id="content-outer"><div id="top-container" style="background-image: url(http://image-paul-blogs.test.upcdn.net/blog/a7.jpg)"><div id="post-info"><div id="post-title"><div class="posttitle">K-均值聚类</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 发表于 2020-03-01<span class="post-meta__separator">|</span><i class="fa fa-history fa-fw" aria-hidden="true"></i> 更新于 2020-03-01</time><span class="post-meta__separator">|</span><span><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><i class="fa fa-angle-right fa-fw" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/">无监督学习</a></span><div class="post-meta-wordcount"><i class="fa fa-file-word-o post-meta__icon fa-fw" aria-hidden="true"></i><span>字数总计:</span><span class="word-count">2.6k</span><span class="post-meta__separator">|</span><i class="fa fa-clock-o post-meta__icon fa-fw" aria-hidden="true"></i><span>阅读时长: 8 分钟</span><div class="post-meta-pv-cv"><span class="post-meta__separator">|</span><span><i class="fa fa-eye post-meta__icon fa-fw" aria-hidden="true"> </i>阅读量:</span><span id="busuanzi_value_page_pv"></span></div></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><script src="/assets/js/APlayer.min.js"> </script><p>聚类是一种无监督学习，将相似对象归为一个簇中，簇内的对象越相似，聚类的效果越好。k-均值聚类是因为它可以发现k个不同的簇，且每个簇的中心采用所含值的均值计算而成。</p>
<p>聚类与分类最大的不同：分类的目标事先已知，而聚类的类别没有预先定义。聚类将相似对象归为一类，不相似对象归为不同簇。<code>相似</code>概念取决于选择的相似的计算方法。</p>
<blockquote>
<p>优点：容易实现</p>
<p>缺点：容易收敛到<strong>局部最小值</strong>，在大规模数据上收敛较慢</p>
</blockquote>
<p>k-均值聚类算法伪代码：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">创建k个质点作为质心(随机选择)</span><br><span class="line">当任意一个点的簇分配结果发生改变时</span><br><span class="line">	对数据集中的每个数据点</span><br><span class="line">    	对每个质心</span><br><span class="line">        	计算质心与数据点之间的距离</span><br><span class="line">        将数据点分配到距其最近的簇</span><br><span class="line">    对每个簇，计算簇中所有点的均值并将均值作为质心</span><br></pre></td></tr></table></figure></div>
<p>k均值算法的性能受所选距离计算方法的影响。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"><span class="comment">#加载文本</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">(fileName)</span>:</span>      <span class="comment">#general function to parse tab -delimited floats</span></span><br><span class="line">    dataMat = []                <span class="comment">#assume last column is target value</span></span><br><span class="line">    fr = open(fileName)<span class="comment">#打开文件</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():<span class="comment">#逐行读取文本</span></span><br><span class="line">        curLine = line.strip().split(<span class="string">'\t'</span>)<span class="comment">#去除多余空格并按制表符切割该字符串返回字符串列表</span></span><br><span class="line">        fltLine = map(float,curLine) <span class="comment">#map all elements to float()</span></span><br><span class="line">        dataMat.append(fltLine)<span class="comment">#封装成列表的列表，容易转换成矩阵</span></span><br><span class="line">    <span class="keyword">return</span> dataMat</span><br><span class="line"><span class="comment">#计算两个向量之间的欧式距离，度量两个向量之间的相似性</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distEclud</span><span class="params">(vecA, vecB)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> sqrt(sum(power(vecA - vecB, <span class="number">2</span>))) <span class="comment">#la.norm(vecA-vecB)</span></span><br><span class="line"><span class="comment">#初始化k个质心</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">randCent</span><span class="params">(dataSet, k)</span>:</span></span><br><span class="line">    n = shape(dataSet)[<span class="number">1</span>]<span class="comment">#获取数据集的特征数</span></span><br><span class="line">    centroids = mat(zeros((k,n)))<span class="comment">#create centroid mat</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(n):<span class="comment">#create random cluster centers, within bounds of each dimension</span></span><br><span class="line">        minJ = min(dataSet[:,j]) <span class="comment">#压缩行，得到j列最小值</span></span><br><span class="line">        rangeJ = float(max(dataSet[:,j]) - minJ)<span class="comment">#j列最大值与最小值之差</span></span><br><span class="line">        centroids[:,j] = mat(minJ + rangeJ * random.rand(k,<span class="number">1</span>))<span class="comment">#得到介于范围的随机取值，注意广播机制，返回k*1的矩阵</span></span><br><span class="line">    <span class="keyword">return</span> centroids<span class="comment">#返回包含k个质点的矩阵</span></span><br></pre></td></tr></table></figure></div>
<blockquote>
<p>random.rand(d1,d2,d3…)生成多维的矩阵，矩阵每个取值是介于0-1的正态分布随机数</p>
</blockquote>
<p><code>loadDataSet()</code>函数将文本文件导入到一个列表中，将每一行为tab分割的浮点数。每个列表会被添加到dataMat中，该返回值是一个包含列表的列表。这种格式容易被封装到矩阵中。</p>
<p><code>distEclud()</code>计算两个向量的<strong>欧式距离</strong>。</p>
<p><code>randCent()</code>函数为给定的数据集构建一个包含k个质心的集合。随机质心必须要在整个数据集的边界之内。这可以通过找到每一维的最小最大值来完成，然后生成0-1.0之间的随机数并通过取值范围和最小值，确保随机点在数据的边界之中。</p>
<p>准备完成后，就可以实现K-均值算法。该算法会创建k个质心，然后将每个点分配到最近的质心，再重新计算质心。重复数次直到簇分配结果不再改变为止。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kMeans</span><span class="params">(dataSet, k, distMeas=distEclud, createCent=randCent)</span>:</span></span><br><span class="line">    m = shape(dataSet)[<span class="number">0</span>]</span><br><span class="line">    clusterAssment = mat(zeros((m,<span class="number">2</span>)))<span class="comment">#create mat to assign data points </span></span><br><span class="line">                                      <span class="comment">#to a centroid, also holds SE of each point</span></span><br><span class="line">    centroids = createCent(dataSet, k)<span class="comment">#随机K个质点</span></span><br><span class="line">    clusterChanged = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">while</span> clusterChanged:</span><br><span class="line">        clusterChanged = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):<span class="comment">#for each data point assign it to the closest centroid</span></span><br><span class="line">            minDist = inf; minIndex = <span class="number">-1</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(k):</span><br><span class="line">                distJI = distMeas(centroids[j,:],dataSet[i,:])<span class="comment">#对数据集中每个点与每个质点的距离进行比较</span></span><br><span class="line">                <span class="keyword">if</span> distJI &lt; minDist:</span><br><span class="line">                    minDist = distJI; minIndex = j<span class="comment">#得到距离每个样本点最近的质点</span></span><br><span class="line">            <span class="keyword">if</span> clusterAssment[i,<span class="number">0</span>] != minIndex: clusterChanged = <span class="literal">True</span><span class="comment">#对质点比较结束后判断该样本点的簇索引是否发生改变</span></span><br><span class="line">            clusterAssment[i,:] = minIndex,minDist**<span class="number">2</span><span class="comment">#更新数据点的簇索引及误差</span></span><br><span class="line">        <span class="keyword">print</span> centroids</span><br><span class="line">        <span class="keyword">for</span> cent <span class="keyword">in</span> range(k):<span class="comment">#recalculate centroids</span></span><br><span class="line">            ptsInClust = dataSet[nonzero(clusterAssment[:,<span class="number">0</span>].A==cent)[<span class="number">0</span>]]<span class="comment">#get all the point in this cluster</span></span><br><span class="line">            centroids[cent,:] = mean(ptsInClust, axis=<span class="number">0</span>) <span class="comment">#assign centroid to mean </span></span><br><span class="line">    <span class="keyword">return</span> centroids, clusterAssment</span><br></pre></td></tr></table></figure></div>
<blockquote>
<p><code>clusterAssment[:,0].A</code>返回所有数据点的簇索引数组，然后找到簇索引为cent的布尔索引。</p>
<p><code>nonzero()[0]</code>：返回布尔索引中不为0，即为true的索引的行索引。利用行索引得到数据集中簇索引为cent的所有数据点。</p>
</blockquote>
<p><code>kmeans()</code>函数接受4个参数。数据集及簇的数目时必选参数，而计算距离和创建初始质心的函数都是可选的。该函数先确定数据集中数据点的个数，然后创建一个矩阵存储每个点的簇分配结果，簇分配结果矩阵<code>clusterAssment</code>包含两列：<strong>一列记录簇索引值</strong>，<strong>第二列存储误差</strong>。误差指当前点到簇质心的距离。可以用该误差评价聚类效果。</p>
<p>按上述方式(<code>计算质心-分配-重新计算</code>)，反复迭代，直到所有数据点的簇分配结果不再改变为止。标志向量<strong>clusterChanged</strong>，如果该值为true。则继续迭代。接下来遍历所有数据找到距离每个点最近的质心，这可以对每个点遍历所有质心并计算点到每个质心的距离来完成。</p>
<p>最后，遍历所有质心并更新它们的取值。实现步骤如下：首先通过数组过滤来获得给定簇的所有点；然后计算所有点的均值，<code>axis=0</code>表示沿矩阵<strong>列方向</strong>进行均值计算；最后程序返回所有类质心与点分配结果。</p>
<p>k均值聚类算法收敛但聚类效果较差的原因是，k均值聚类算法收敛到了局部最小值，而非全局最小值。一种用于度量聚类效果的指标是SSE，即平方误差和。SSE越小，说明数据点越接近它们的质心，聚类效果也越好。一种降低SSE值的方法是增加簇数目，但违背了聚类的目标，聚类的目标是在保持簇数目不变的情况下提高簇的质量。</p>
<p>为了克服k-均值聚类算法收敛于局部最小值的问题，有人提出了另一种被称为二分K-均值的算法，该算法首先将所有点作为一个簇，然后将该簇一分为二。之后选择其中一个簇继续划分，选择哪一个簇进行划分取决于对其划分是否可以最大降低SSE的值。上述基于SSE的划分过程不断重复，直到得到用户指定的簇数目为止。</p>
<p>二分K-均值伪代码如下：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">将所有点看成一个簇</span><br><span class="line">当簇数目小于k时</span><br><span class="line">对于每一个簇</span><br><span class="line">	计算总误差</span><br><span class="line">    在给定的簇上面进行k-均值聚类(k=<span class="number">2</span>)</span><br><span class="line">    计算将该簇一分为二之后的总误差</span><br><span class="line">选择使得误差最小的那个簇进行划分操作</span><br></pre></td></tr></table></figure></div>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">biKmeans</span><span class="params">(dataSet, k, distMeas=distEclud)</span>:</span></span><br><span class="line">    m = shape(dataSet)[<span class="number">0</span>]</span><br><span class="line">    clusterAssment = mat(zeros((m,<span class="number">2</span>)))<span class="comment">#生成m*2大小的零矩阵</span></span><br><span class="line">    centroid0 = mean(dataSet, axis=<span class="number">0</span>).tolist()[<span class="number">0</span>]<span class="comment">#对数据集按列求均值，并转换成列表</span></span><br><span class="line">    centList =[centroid0] <span class="comment">#初始化质心列表，只含有一个质心</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(m):<span class="comment">#计算数据集样本点的初始误差</span></span><br><span class="line">        clusterAssment[j,<span class="number">1</span>] = distMeas(mat(centroid0), dataSet[j,:])**<span class="number">2</span></span><br><span class="line">    <span class="keyword">while</span> (len(centList) &lt; k):</span><br><span class="line">        lowestSSE = inf</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(centList)):<span class="comment">#遍历每个簇，对每个簇进行分裂</span></span><br><span class="line">            ptsInCurrCluster = dataSet[nonzero(clusterAssment[:,<span class="number">0</span>].A==i)[<span class="number">0</span>],:]<span class="comment">#get the data points currently in cluster i</span></span><br><span class="line">            centroidMat, splitClustAss = kMeans(ptsInCurrCluster, <span class="number">2</span>, distMeas)<span class="comment">#返回质心矩阵与数据集簇索引矩阵</span></span><br><span class="line">            sseSplit = sum(splitClustAss[:,<span class="number">1</span>])<span class="comment">#compare the SSE to the currrent minimum</span></span><br><span class="line">            sseNotSplit = sum(clusterAssment[nonzero(clusterAssment[:,<span class="number">0</span>].A!=i)[<span class="number">0</span>],<span class="number">1</span>])<span class="comment">#</span></span><br><span class="line">            <span class="keyword">print</span> <span class="string">"sseSplit, and notSplit: "</span>,sseSplit,sseNotSplit</span><br><span class="line">            <span class="keyword">if</span> (sseSplit + sseNotSplit) &lt; lowestSSE:<span class="comment">#分裂后与分裂前的误差进行比较</span></span><br><span class="line">                bestCentToSplit = i<span class="comment">#得到这一轮分裂效果最好的簇索引</span></span><br><span class="line">                bestNewCents = centroidMat<span class="comment">#得到分裂效果最好的质心矩阵</span></span><br><span class="line">                bestClustAss = splitClustAss.copy()<span class="comment">#得到数据集簇索引矩阵的副本</span></span><br><span class="line">                lowestSSE = sseSplit + sseNotSplit<span class="comment">#更新当前误差</span></span><br><span class="line">        bestClustAss[nonzero(bestClustAss[:,<span class="number">0</span>].A == <span class="number">1</span>)[<span class="number">0</span>],<span class="number">0</span>] = len(centList) <span class="comment">#更新分裂后数据集的簇索引</span></span><br><span class="line">        bestClustAss[nonzero(bestClustAss[:,<span class="number">0</span>].A == <span class="number">0</span>)[<span class="number">0</span>],<span class="number">0</span>] = bestCentToSplit</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'the bestCentToSplit is: '</span>,bestCentToSplit</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'the len of bestClustAss is: '</span>, len(bestClustAss)</span><br><span class="line">        centList[bestCentToSplit] = bestNewCents[<span class="number">0</span>,:].tolist()[<span class="number">0</span>]<span class="comment">#更新质点矩阵 </span></span><br><span class="line">        centList.append(bestNewCents[<span class="number">1</span>,:].tolist()[<span class="number">0</span>])</span><br><span class="line">        clusterAssment[nonzero(clusterAssment[:,<span class="number">0</span>].A == bestCentToSplit)[<span class="number">0</span>],:]= bestClustAss<span class="comment">#重新计算误差</span></span><br><span class="line">    <span class="keyword">return</span> mat(centList), clusterAssment<span class="comment">#返回质点集合与数据集簇索引矩阵</span></span><br></pre></td></tr></table></figure></div>
<blockquote>
<p><code>mean(dataSet,axis=0)</code>,对每列求均值，压缩行，返回一个<strong>1*n</strong>的矩阵，<code>tolist()</code>将其转换为列表的形式，即[[]]，取第一个元素[0],则得到[]列表。</p>
</blockquote>
<p>该函数首先创建一个矩阵来存储数据集中每个点的簇分配结果及平方误差，然后计算整个数据集的质心，并使用一个列表保留所有质心。得到质心后，就可以遍历数据集中所有点来计算每个点到质心的误差值。</p>
<p>在while循环中，不停的对簇进行划分，直到得到想要的簇数目为止。然后遍历所有簇来决定最佳的簇进行划分。为此需要比较划分前后的SSE值。对每个簇，将该簇中的所有点看成一个小的数据集<strong>ptsInCurrCluster</strong>。将<strong>ptsIncurrCluster</strong>输入函数<code>kMeans()</code>中进行处理**(k=2)**.k-均值算法会生成两个质心(簇)，同时给出每个簇的误差值。这些误差与剩余数据集的误差作为本次划分的误差。如果该划分的SSE值最小，则本次划分被保存。一旦决定了要划分的簇，接下来要实际执行划分操作，即将要划分的簇中所有点的簇分配结果进行修改即可。当使用<code>kMeans()</code>函数并且指定簇数位2时，会得到两个编号分别为0和1的结果簇。需要将这些簇编号修改为划分簇及新加簇的编号，该过程通过两个数组过滤器来完成。最后新的簇分配结果被更新，新的质心会被添加到<code>centList</code>中。</p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Paul Yu</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://yoursite.com/2020/03/01/K-%E5%9D%87%E5%80%BC%E8%81%9A%E7%B1%BB/">http://yoursite.com/2020/03/01/K-%E5%9D%87%E5%80%BC%E8%81%9A%E7%B1%BB/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://yoursite.com">哈皮🐖</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%81%9A%E7%B1%BB/">聚类    </a></div><div class="post_share"><div class="social-share" data-image="http://image-paul-blogs.test.upcdn.net/blog/a7.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-button button--primary button--animated"> <i class="fa fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="lazyload post-qr-code__img" src="/img/wechat.png" alt="微信"><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="lazyload post-qr-code__img" src="/img/alipay.png" alt="支付寶"><div class="post-qr-code__desc">支付寶</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2020/03/12/%E5%8F%AF%E8%A7%86%E5%8C%96%E4%B9%8BMatplotlib(%E4%B8%80)/"><img class="prev_cover lazyload" data-src="http://image-paul-blogs.test.upcdn.net/blog/a17.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="label">上一篇</div><div class="prev_info"><span>可视化之Matplotlib(一)</span></div></a></div><div class="next-post pull_right"><a href="/2020/02/24/%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/"><img class="next_cover lazyload" data-src="http://image-paul-blogs.test.upcdn.net/blog/a7.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="label">下一篇</div><div class="next_info"><span>流量分类论文总结</span></div></a></div></nav><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> 评论</span></div><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: 'b7cd8445bdb1b19631d9',
  clientSecret: '7d1af09b37d2980e12c8d08d4749917555bc2cef',
  repo: 'nicePaul521.github.io',
  owner: 'nicePaul521',
  admin: 'nicePaul521',
  id: md5(decodeURI(location.pathname)),
  language: 'zh-CN',
  updateCountCallback: commentCount
})
gitalk.render('gitalk-container')

function commentCount(n){
  document.getElementsByClassName('gitalk-comment-count')[0].innerHTML= n
}</script></div></div></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 By Paul Yu</div><div class="framework-info"><span>驱动 </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div><div class="footer_custom_text">hi,welcome to my<a href="https://nicepaul.top/" target="_blank" rel="noopener"> blog</a>!</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">繁</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/calendar.js"></script><script src="/js/languages.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script><script src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/js/click_heart.js"></script><script src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/js/ClickShowText.js"></script></body></html>